{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML pipeline\n",
    "\n",
    "After the data exploration in the \"House_prices\" notebook I can streamline my preprocessing and training into a ML Pipeline. \n",
    "Following the blog here I write some custom transformers to preprocess the data. \n",
    "https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65\n",
    "Then combine with one hot encoders/imputation/scalers etc to build a pipeline.\n",
    "\n",
    "I then apply the combined pipeline to the kaggle test set and make submissions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "# possible models\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# read data and split into X,y\n",
    "data = pd.read_csv('C:/Users/Jacob/Dropbox/Side Projects/Kaggle/House Prices in Ames, Iowa/house-prices-advanced-regression-techniques/train.csv',index_col=0)\n",
    "X = data.drop('SalePrice', axis = 1)\n",
    "y = data.pop('SalePrice').to_numpy().reshape(-1, 1).astype('float')   # not normalising this at the mo.\n",
    "scaler_y = StandardScaler()\n",
    "y = pd.DataFrame(scaler_y.fit_transform(y))\n",
    "y = y.values.ravel()\n",
    "\n",
    "# The data has 80 columns so this stops pandas from supressing the full output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical pre-processing\n",
    "# Custom transformer that drops PoolQC, Fence, MiscFeature because they have too many NaNs\n",
    "# Fills alley NaN's with 'None'\n",
    "# Some NaNs in other features but these are dealt with later\n",
    "class CategoricalTransformer( BaseEstimator, TransformerMixin ):\n",
    "    # Don't need class constructor\n",
    "        \n",
    "    #Return self nothing else to do here\n",
    "    def fit( self, X, y = None  ):\n",
    "        return self\n",
    "    \n",
    "    #Transformer method we wrote for this transformer \n",
    "    def transform(self, X , y = None ):\n",
    "        X.fillna('None', inplace=True)\n",
    "        X.loc[:,'MSSubClass'] = X.loc[:,'MSSubClass'].apply(str) # convert MSSubClass to string so it can be one hot encoded\n",
    "        \n",
    "        return X.values\n",
    "\n",
    "#Defining the steps in the categorical pipeline\n",
    "categorical_features = ['MSSubClass'] + list(X.select_dtypes(include=object))\n",
    "categorical_pipeline = Pipeline( steps = [     ( 'cat_transformer', CategoricalTransformer() ), \n",
    "                                  ( 'one_hot_encoder', OneHotEncoder() ) ] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical preprocessing\n",
    "# Custom transformer that converts to float, drops 'GarageYrBlt','1stFlrSF','TotRmsAbvGrd','GarageCars' due to strong correlation with other features, \n",
    "# and fills in NaNs in LotFrontage, MasVnrArea with the mean values for each row\n",
    "class NumericalTransformer(BaseEstimator, TransformerMixin):\n",
    "    #Don't need class constructor\n",
    "    \n",
    "    #Return self, nothing else to do here\n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Custom transform method we wrote that creates aformentioned features and drops redundant ones \n",
    "    def transform(self, X, y = None):\n",
    "        # make all entries floats\n",
    "        X.astype('float64', inplace=True)\n",
    "        \n",
    "        # drop some columns\n",
    "        X.drop(columns=['GarageYrBlt','1stFlrSF','TotRmsAbvGrd','GarageCars'], inplace=True)\n",
    "        \n",
    "        return X.values\n",
    "\n",
    "#Defining the steps in the numerical pipeline     \n",
    "numerical_features = list(X.select_dtypes(exclude=object))\n",
    "numerical_features.remove('MSSubClass')\n",
    "numerical_pipeline = Pipeline( steps = [ \n",
    "                                  \n",
    "                                  ( 'num_transformer', NumericalTransformer() ),\n",
    "                                  \n",
    "                                  ( 'imputer', SimpleImputer(strategy = 'median') ),\n",
    "                                  \n",
    "                                  ( 'std_scaler', StandardScaler() ) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kaggle score on the test set is: 0.13755252408330151\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y , test_size = 0.2 , random_state = 42 )\n",
    "\n",
    "#The full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline = Pipeline( steps = [  ( 'preprocessor', preprocessor),\n",
    "                                  ( 'model', GradientBoostingRegressor(n_estimators = 750) ) ] )\n",
    "\n",
    "#Can call fit on it just like any other pipeline\n",
    "full_pipeline.fit( X_train, y_train )\n",
    "\n",
    "#Can predict with it like any other pipeline\n",
    "y_pred = full_pipeline.predict( X_test ) \n",
    "\n",
    "# def kaggle_score(y_true, y_pred):\n",
    "#     return np.sqrt(mean_squared_error(np.log(y_pred), np.log(y_true)))\n",
    "\n",
    "def kaggle_score(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.log(scaler_y.inverse_transform([y_pred])), np.log(scaler_y.inverse_transform([y_true]))))\n",
    "\n",
    "print('The kaggle score on the test set is:',kaggle_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'model__n_estimators': 800}\n",
      "\n",
      "-0.13 (+/-0.03) for {'model__n_estimators': 800}\n",
      "-0.13 (+/-0.032) for {'model__n_estimators': 750}\n",
      "-0.13 (+/-0.029) for {'model__n_estimators': 700}\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "\n",
    "kaggle_scorer = make_scorer(kaggle_score, greater_is_better=False)\n",
    "\n",
    "# helper function to display CV results.\n",
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))\n",
    "        \n",
    "parameters = {}\n",
    "parameters['model__n_estimators'] = [1000, 750, 500]\n",
    "\n",
    "cv = GridSearchCV(full_pipeline, parameters, cv=5, scoring=kaggle_scorer)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print_results(cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Kaggle test set\n",
    "X_test_kaggle = pd.read_csv('C:/Users/Jacob/Dropbox/Side Projects/Kaggle/House Prices in Ames, Iowa/house-prices-advanced-regression-techniques/test.csv',index_col=0)\n",
    "y_pred_kaggle = full_pipeline.predict(X_test_kaggle)\n",
    "y_pred_kaggle = scaler_y.inverse_transform([y_pred_kaggle])\n",
    "\n",
    "# save submission\n",
    "submission = pd.read_csv('C:/Users/Jacob/Dropbox/Side Projects/Kaggle/House Prices in Ames, Iowa/house-prices-advanced-regression-techniques/sample_submission.csv',index_col=0)\n",
    "submission.loc[:,'SalePrice'] = y_pred_kaggle.T\n",
    "submission.to_csv('submission3.csv')\n",
    "\n",
    "# sb 1\n",
    "# 2778 out of 5405. Just behind halfway. Score of 0.13820\n",
    "# sub 2\n",
    "# didnt inverse scale so awful score of ~11.\n",
    "# sub 3\n",
    "# 2393 out of 5413. Over half way!!!! 0.13327"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions:\n",
    "1. score of 0.13820. Position 2778 out of 5405. \n",
    "2. made error. score got way worse\n",
    "3. score of 0.13327. Positon 2393 out of 5413. big jump forwards! :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
