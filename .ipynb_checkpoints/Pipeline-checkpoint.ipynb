{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline \n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "\n",
    "data = pd.read_csv('C:/Users/Jacob/Dropbox/Side Projects/Kaggle/House Prices in Ames, Iowa/house-prices-advanced-regression-techniques/train.csv',index_col=0)\n",
    "X = data.drop('SalePrice', axis = 1)\n",
    "y = data['SalePrice']    # not normalising this at the mo.\n",
    "\n",
    "# The data has 80 columns so this stops pandas from supressing the full output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical pre-processing\n",
    "# Custom transformer that drops PoolQC, Fence, MiscFeature because they have too many NaNs\n",
    "# Fills alley NaN's with 'None'\n",
    "# Some NaNs in other features but these are dealt with later\n",
    "class CategoricalTransformer( BaseEstimator, TransformerMixin ):\n",
    "    # Don't need class constructor\n",
    "        \n",
    "    #Return self nothing else to do here\n",
    "    def fit( self, X, y = None  ):\n",
    "        return self\n",
    "    \n",
    "    #Transformer method we wrote for this transformer \n",
    "    def transform(self, X , y = None ):\n",
    "        X.fillna('None', inplace=True)\n",
    "        X.loc[:,'MSSubClass'] = X.loc[:,'MSSubClass'].apply(str) # convert MSSubClass to string so it can be one hot encoded\n",
    "        \n",
    "        return X.values\n",
    "\n",
    "#Defining the steps in the categorical pipeline\n",
    "categorical_features = ['MSSubClass'] + list(X.select_dtypes(include=object))\n",
    "categorical_pipeline = Pipeline( steps = [     ( 'cat_transformer', CategoricalTransformer() ), \n",
    "                                  \n",
    "                                  ( 'one_hot_encoder', OneHotEncoder() ) ] )\n",
    "\n",
    "#( 'cat_selector', FeatureSelector(categorical_features) ),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical preprocessing\n",
    "# Custom transformer that converts to float, drops 'GarageYrBlt','1stFlrSF','TotRmsAbvGrd','GarageCars' due to strong correlation with other features, \n",
    "# and fills in NaNs in LotFrontage, MasVnrArea with the mean values for each row\n",
    "class NumericalTransformer(BaseEstimator, TransformerMixin):\n",
    "    #Don't need class constructor\n",
    "    \n",
    "    #Return self, nothing else to do here\n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Custom transform method we wrote that creates aformentioned features and drops redundant ones \n",
    "    def transform(self, X, y = None):\n",
    "        # make all entries floats\n",
    "        X.astype('float64', inplace=True)\n",
    "        \n",
    "        # drop some columns\n",
    "        X.drop(columns=['GarageYrBlt','1stFlrSF','TotRmsAbvGrd','GarageCars'], inplace=True)\n",
    "        \n",
    "        return X.values\n",
    "\n",
    "#Defining the steps in the numerical pipeline     \n",
    "numerical_features = list(X.select_dtypes(exclude=object))\n",
    "numerical_features.remove('MSSubClass')\n",
    "numerical_pipeline = Pipeline( steps = [ \n",
    "                                  \n",
    "                                  ( 'num_transformer', NumericalTransformer() ),\n",
    "                                  \n",
    "                                  ( 'imputer', SimpleImputer(strategy = 'median') ),\n",
    "                                  \n",
    "                                  ( 'std_scaler', StandardScaler() ) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine pipelines\n",
    "#full_pipeline = FeatureUnion( transformer_list = [ ( 'categorical_pipeline', categorical_pipeline ), ( 'numerical_pipeline', numerical_pipeline ) ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kaggle score on the test set is: 0.14160734272334927\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y , test_size = 0.2 , random_state = 42 )\n",
    "\n",
    "#The full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline = Pipeline( steps = [  ( 'preprocessor', preprocessor),\n",
    "                                  ( 'model', GradientBoostingRegressor(n_estimators = 1000) ) ] )\n",
    "\n",
    "#Can call fit on it just like any other pipeline\n",
    "full_pipeline.fit( X_train, y_train )\n",
    "\n",
    "#Can predict with it like any other pipeline\n",
    "y_pred = full_pipeline.predict( X_test ) \n",
    "\n",
    "def kaggle_score(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.log(y_pred), np.log(y_true)))\n",
    "\n",
    "print('The kaggle score on the test set is:',kaggle_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'model__n_estimators': 500}\n",
      "\n",
      "-0.135 (+/-0.033) for {'model__n_estimators': 100}\n",
      "-0.131 (+/-0.03) for {'model__n_estimators': 200}\n",
      "-0.129 (+/-0.031) for {'model__n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "\n",
    "kaggle_scorer = make_scorer(kaggle_score, greater_is_better=False)\n",
    "\n",
    "# helper function to display CV results.\n",
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))\n",
    "        \n",
    "parameters = {}\n",
    "parameters['model__n_estimators'] = [100, 200, 500]\n",
    "\n",
    "cv = GridSearchCV(full_pipeline, parameters, cv=5, scoring=kaggle_scorer)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print_results(cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle test set\n",
    "X_test_kaggle = pd.read_csv('C:/Users/Jacob/Dropbox/Side Projects/Kaggle/House Prices in Ames, Iowa/house-prices-advanced-regression-techniques/test.csv',index_col=0)\n",
    "y_pred_kaggle = full_pipeline_m.predict(X_test_kaggle)\n",
    "\n",
    "submission = pd.read_csv('C:/Users/Jacob/Dropbox/Side Projects/Kaggle/House Prices in Ames, Iowa/house-prices-advanced-regression-techniques/sample_submission.csv',index_col=0)\n",
    "submission.loc[:,'SalePrice'] = y_pred_kaggle.T\n",
    "submission.to_csv('submission.csv')\n",
    "\n",
    "# 2778 out of 5405. Just behind halfway. Score of 0.13820"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how to dig down\n",
    "# # check strat\n",
    "# strat = full_pipeline_m.get_params()['full_pipeline'].get_params()['transformer_list'][1][1].get_params()['imputer'].get_params()['strategy']\n",
    "# print(strat)\n",
    "# # change strat\n",
    "# full_pipeline_m.set_params(full_pipeline__numerical_pipeline__imputer__strategy = 'mean')\n",
    "# # check strat\n",
    "# strat = full_pipeline_m.get_params()['full_pipeline'].get_params()['transformer_list'][1][1].get_params()['imputer'].get_params()['strategy']\n",
    "# print(strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate categorical and numerical data.\n",
    "# # Custom Transformer that extracts columns passed as argument to its constructor \n",
    "# class FeatureSelector( BaseEstimator, TransformerMixin ):\n",
    "#     #Class Constructor \n",
    "#     def __init__( self, feature_names ):\n",
    "#         self._feature_names = feature_names \n",
    "    \n",
    "#     #Return self nothing else to do here    \n",
    "#     def fit( self, X, y = None ):\n",
    "#         return self \n",
    "    \n",
    "#     #Method that describes what we need this transformer to do\n",
    "#     def transform( self, X, y = None ):\n",
    "#         return X.reindex(columns = self._feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
